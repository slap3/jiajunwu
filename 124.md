
# 课程内容说明
#
### 特别说明：章节总结及代码标注一定程度上借助了chapgpt 4
###
##

1. **生成式人工智能的定义**：让机器产生复杂有结构的物件，如文章、语音、影像等，从近乎无穷的可能中找出适当组合，与分类（从有限选项中选择）不同。
2. **实现手段：**
   机器学习与深度学习。机器学习是机器自动从资料找函数，深度学习是更厉害的手段，今日的生成式人工智能多以深度学习达成，如ChatGPT、AI画图等模型都有上亿个参数。
3.  **生成策略:**
  语言模型：文章由文字构成，通过Autoregressive Generation依序生成文字。
图片生成：图片由像素构成，有类似语言模型的生成策略。
##
# prompt_part1
#
1. **生成式人工智能的能力**
    - **多领域应用**：如ChatGPT能进行文本生成、语言翻译等多种任务，功能广泛。
    - **工具进化**：可以处理各种不同类型的任务，且同一任务可能有多种解法。
2. **使用与应对策略**
    - **明确需求下达指令**：使用者应明确自己的需求，给人工智能下达清晰的指令，以获得更符合期望的结果，
    - **训练自己的模型**：训练自己的模型（如使用开源模型LLaMA），调整函数以满足特定需求。
3. **模型评估挑战**
    - **任务多样性与复杂性**：全面评估模型并不容易难度很大。
    - **内容管理**：模型需要防止说出有害内容，如脏话、抄袭、歧视等言论。
# prompt_part2
#
1. **强化语言模型的方法**
    - **拆解任务**
        - 可先拆解为多个步骤，模型还可检查自己的错误。
        - 同一问题模型每次答案可能不同，复杂任务可通过Self - Consistency等方法拆解成多步骤处理。
    - **使用工具**
        - **计算与信息获取**：语言模型有不擅长的事（如算数），但可使用工具。
        - **专业问题解答与创作辅助**：对于专业问题，模型可先搜索相关信息再回答，可利用工具辅助完成。
    - **模型合作**
        - **专业分工**：未来语言模型可专业分工，不同团队专注打造不同领域专业模型，让合适模型做合适任务。
        - **模型讨论与反思**：模型可彼此讨论、反省。
# prompt_part3
#
1. **模型合作方式**
    - **专业分工协作**：未来语言模型可进行专业分工，根据任务输入判断合适模型来完成任务模型合作能让合适模型做合适事情。
    - **模型相互讨论**
        - **讨论与反思**：模型间可相互讨论、反省。
        - **多模型讨论及规则**：增加讨论模型数量或轮次可能影响结果准确性。
2. **引入角色完成项目**
    - **团队角色设定**：引入不同角色来完成项目。
# LLMtraining_part1
#
1. **文字接龙学习基础**
    - **原理**：以未完成句子预测下一个token的方式进行文字接龙学习，模型（如Transformer）是有数十亿未知参数的函数，通过训练资料利用机器学习找出这些参数。
    - **阶段特点**
        - **自我学习，累积实力**：使用大量文字资料（如网络上各种文本）学习文字接龙，资料量可按需获取，人工介入较少。
        - **名帅指点，发挥潜力**：在之前的GPT系列中，模型大小和数据量不断发展。
        - **参与实战，打磨技巧**：语言模型虽从网络资料中学到很多，但还需要进一步训练来提升实际应用能力。
2. **训练面临的挑战与解决方法**
    - **挑战**
        - **找参数的挑战**：训练可能失败（找到的参数不符合训练资料），此时需更换超参数重新训练。
        - **模型合理性问题**：机器学习只管参数是否符合训练资料，不管是否合理）。
    - **解决方法**
        - **增加训练资料多样性**：可使找到的参数更合理。
        - **调整初始参数**：“train from scratch”通过随机设定初始参数，使最终参数比较接近初始化参数；“先验知识”则是寻找“好”的初始参数，使参数更可能合理，但“好”的初始参数获取存在困难。

# LLMtraining_part2
#
1. **人类老师教导与微调**
    - **督导式学习（Supervised Learning）**：通过人力进行资料标注，但人力成本高，无法收集太多资料。。
    - **微调路线**
        - **路线一：打造一堆专才**：针对不同任务（如翻译、编修等）分别训练专才模型。
        - **路线二：直接打造一个通才**：收集涵盖各种任务的大量标注资料训练通才模型。
2. **Instruction Fine - tuning的重要性及实践**
    - **重要性**：Instruction Fine - tuning被视为画龙点睛，高质量的Instruction Fine - tuning资料对提升模型效果至关重要，少量高质量标注数据即可达到较好效果。
    - **实践方法**：可以ChatGPT为参考进行逆向工程，先让ChatGPT想任务，再根据任务想可能输入，最后产生答案，如撰写邮件任务。
3. **模型发展与开源情况**
    - **模型开源**：Meta开源了LLaMA，在此基础上出现了Alpaca、Vicuna等模型，它们使用不同数据集、训练代码、评估指标，训练成本也有所不同。
    - **模型应用拓展**：进入人人可以fine - tune大型语言模型的时代，出现了众多基于LLaMA等的模型，有不同的数据使用和训练方式，部分模型还具有多模态能力。
# LLMtraining_part3
#
1. **强化学习（RLHF）概述**
    - **训练阶段**：大型语言模型训练分为三个阶段，第一阶段自我学习积累实力（如通过自督导式学习Self - supervised Learning），第二阶段名师指点发挥潜力（如督导式学习Supervised Learning中的Instruction Fine - tuning），第三阶段参与实战打磨技巧（如强化学习Reinforcement Learning中的RLHF）。
    - **RLHF原理**：语言模型在RLHF阶段进入新的“思考模式”，学习对生成结果做通盘考量。
2. **RLHF与Instruction Fine - tuning对比**
    - **Instruction Fine - tuning**：模型学习按照人类老师给定的正确答案进行接龙。
    - **RLHF优势**：在某些情况下，人类写出正确答案不易但容易判断好坏时，RLHF更适用。它使模型能从人类反馈中学习，生成更符合人类期望的结果。
3. **语言模型与AlphaGo对比**
    - **学习方式**
    - **语言模型**：第一阶段（Pre - train）和第二阶段（Instruction Fine - tuning）主要是人类老师说什么就跟着说什么，在RLHF阶段则需要人类反馈来优化。
    - **任务性质**：下围棋的每一步是分类问题，但整体来看也是生成式学习；语言模型则是通过生成文字来完成任务，如对话、回答问题等。
4. **RLHF的难题与待解议题**
    - **难题**：RLHF面临着如何平衡Helpfulness（有用性）和Safety（安全性）的难题。
    - **待解议题**：存在人类自己都无法正确判断好坏的状况，或者人的判断可能是错误的情况。
# agent
#
本文主要介绍了以大型语言模型打造的AI Agent，包括其现状、示例、与普通语言模型的区别、面临的挑战以及相关技术，具体内容如下：
1. **AI Agent概述**
    - **现状与期望**：目前多数人使用AI的方式较为单一，而未来人类期望AI Agent能更自主地完成任务。
2. **AI Agent与普通语言模型对比**
    - **普通语言模型的局限**：以ChatGPT为例，每次开始新对话时一切都重头来过，缺乏记忆功能。
    - **AI Agent的优势**：AI Agent具有记忆功能，能够在执行任务过程中积累经验，并根据经验调整行动。
3. **AI Agent面临的挑战与技术**
    - **挑战**：在执行任务时，AI Agent需要应对复杂多变的外界环境。
    - **技术**：涉及强化学习（Reinforcement Learning）相关技术。
# explain
#
本文主要探讨了大型语言模型的可解释性相关问题，包括其作为“黑盒子”的现状、如何使其可解释的方法、面临的问题及一些相关研究，具体内容如下：
1. **大型语言模型的“黑盒子”现状**
    - **透明度问题**：人们对其内部机制一无所知，尽管知道模型参数、训练资料与过程，但仍难以理解其决策过程。
    - **可解释性分类**：可解释性分为Interpretable（思维透明）和Explainable（可解释）。
2. **实现大型语言模型可解释性的方法**
    - **找出影响输出的关键输入**
        - **Gradient - based Approach**：通过观察每个输入的改变对输出的影响。
        - **分析Attention**：研究注意力机制，以确定输入中哪些部分对输出影响较大。
        - **In - context learning**：观察模型如何基于上下文学习和做出决策。
    - **找出影响输出的关键训练资料**：以对“shutdown”问题的回答为例，不同参数模型的回答受不同训练资料影响，较大模型有跨语言学习能力。
    - **分析Embedding中存储的信息**
        - **词性关系**：探究语言模型是否知道输入词汇的词性。
        - **可视化**：将信息投影到二维平面上以便于可视化分析。
3. **其他相关内容**
    - **语言模型的“测谎器”**：利用语言模型判断语句真假，通过概率分析得出结论。
    - **用AI解释AI**：可以用一个语言模型（如GPT - 4）来解释另一个语言模型（如GPT - 2）。
    - **直接询问语言模型**：语言模型会说话，可通过询问获取解释。
# transformer
#

1. **模型演进中的Transformer**
    - **模型发展历程**：语言模型经历了从N - gram、Feed - forward Network、Recurrent Neural Network（RNN）到Transformer的发展，Transformer是当前语言模型（如ChatGPT）的重要组成部分，本课程对Transformer的说明进行了简化，详细内容可参考过去课程。
2. **Transformer概述**
    - **工作流程**：Transformer主要包括Tokenization、Input Layer、Attention、Feed - Forward、Output Layer等部分，通过这些步骤实现文字接龙，即输入文字，将其转换为Token，理解Token（包括语义和位置信息），考虑上下文，进行整合、思考等操作后得到输出，可反复思考优化输出。
3. **Transformer各部分详解**
    - **Tokenization（把文字变成Token）**：语言模型以Token为单位处理文字。
    - **理解每个Token（语义和位置）**
        - **语义理解**：每个Token通过训练得到对应的向量（Embedding）。
        - **位置理解**：每个位置有独特的向量Positional Embedding，也是在训练时得到的参数，用于表示Token在文本中的位置信息。
    - **Attention（考虑上下文）**
        - **原理**：Attention机制主要贡献是发现不需要RNN，仅靠Attention即可。其工作过程包括找出相关Token并计算相关性，通过计算得到Attention Weight，集合相关信息。计算相关性时会得到Attention Matrix，实作时通常采用Causal Attention，只考虑左边的Token。此外，关联 性存在多种类型，如通过Multi - head Attention可从不同角度计算相关性并整合信息。
    - **Feed - Forward**：在Transformer Block中，经过Attention后会进行Feed - Forward操作，这部分内容在文档中未详细展开，但它是Transformer工作流程中的重要环节，与Attention等部分共同协作实现模型功能，多个Transformer Block（如Layer 1、Layer 2等）依次处理信息，最后通过Output Layer（包含Linear Transformer和Softmax）得到最终输出。
# evaluation
#
本文主要讲述了语言模型能力的评估相关内容，包括评估方式、面临的问题、不同的评估基准以及其他相关考虑因素，具体如下：
1. **语言模型能力评估方式**
    - **与标准答案对比**：通过将模型的输出与标准答案进行对比来评估模型能力，与标准答案不同并不一定代表错误，评估指标如BLEU（用于翻译）、ROUGE（用于摘要）主要做字面比对。
    - **人工评估与模型评估**：人工评估可能相对准确，但耗时费力；也可以用强大的语言模型来评估其他模型（如MT - Bench）。
2. **评估面临的问题**
    - **答案的多样性与模糊性**：如选择题中模型可能输出不规范，对于一些问题可能存在多种合理答案或难以界定绝对正确的答案，导致评估困难。
    - **模型的不确定性**：语言模型的输出具有一定随机性，且可能受到训练数据、模型本身特点等因素影响，使得评估结果不稳定。
    - **其他方面**：除了评估模型效能，还需考虑人工智慧的安全性（如防止模型唬烂、被骗、产生偏见、抄袭等），同时模型的价格、速度等也是实际应用中需要考虑的因素。
# ethical
#
本文主要讲述了大型语言模型的安全性议题，包括语言模型的错误类型、评估偏倚的方法、政治倾向、减轻偏倚的措施、检测AI生成内容的方法以及语言模型在学术领域应用中的问题，具体内容如下：
1. **语言模型的错误与应对措施**
    - **错误类型 - Hallucination**：语言模型会犯错，如产生幻觉（输出与事实不符的内容）。
    - **应对错误 - 事实核查示例**：尽管有些模型会进行事实核查，但仍可能提供与事实不完全相符或有遗漏的信息。
2. **语言模型的偏倚评估**
    - **评估方法**
        - **情感分析差异**：通过对比不同文本在语言模型中的情感分析得分差距，来初步判断模型是否存在偏倚。
        - **红队测试**：由专门负责想产生偏见输入的团队（红队），通过修改性别相关词汇等方式，利用强化学习最大化差距，评估模型在性别等方面的偏倚情况。
    - **偏倚表现**
        - **职业性别刻板印象**：在生成职业表现反馈时，语言模型（如ChatGPT）对不同职业（如幼儿园老师和建筑工人）使用的代词存在差异，体现出对职业性别的刻板印象。
        - **种族歧视争议**：在审查履历时，语言模型（如GPT）对不同种族和性别的名字存在偏好差异，引发种族歧视争议。
3. **语言模型的政治倾向**
    - **倾向测试**：通过让语言模型选择对政治观点的态度选项，以及利用相关工具进行政治倾向测试，发现不同模型倾向不一。
4. **减轻偏倚的方法**
    - **方法分类**：主要包括预处理（Pre - Processing，改变模型输入，如训练数据或提示）、训练中处理、处理中和后处理，详细内容可参考概述论文。
5**语言模型输出浮水印**
    - **浮水印概念**：为解决语言模型输出内容难以辨别来源的问题，可在模型输出中加上人类难以辨识的暗号。
# injection
#
1. **Jailbreaking**
    - **概念与攻击对象**：针对语言模型本身，试图让语言模型说出不该讲的话，类比于人类社会中的杀人放火等违反规则的行为。
    - **攻击方式**
        - **使用不熟悉语言**：如用特定语言（非通用语言）询问如何砍倒停车标志，模型可能会给出工具和步骤，而正常情况下应拒绝回复。
        - **给予冲突指令**：以特定开头要求回答砍倒停车标志所需工具，模型可能会提供相关工具信息，违背正常的安全和法律原则。
        - **试图说服模型**：通过编写停车标志作恶的故事等方式试图说服模型，使其在面对非法问题（如砍倒停车标志）时提供帮助。
    - **目的**：除了获取非法或不适当信息外，还可用于训练数据重建，如获取个人隐私信息或让模型执行异常操作。
2. **Prompt Injection（提示注入）**
    - **概念与攻击对象**：针对以语言模型打造的应用（如AI助教），让语言模型在不恰当时机做不恰当事情。
    - **攻击示例**：在AI助教评估文章作业的场景中，通过特定指令，使模型偏离正常评估任务，给出不符合实际的分数。
    - **相关比赛**：有Prompt Injection比赛，涉及多种攻击技术（如Context Overflow、Compound Instruction、Cognitive Hacking等，具体如递归、特殊情况处理、风格注入、上下文忽略、虚拟化、代码注入、语法转换等多种方式。
# strategy
#
1. **生成式人工智能基础**
    - **构成要素**：生成式人工智能旨在让机器产生复杂有结构的物件，如文字、影像、声音等。
    - **本质**：将基本单位按正确排序组合，在不同应用场景（如绘图AI、对话AI、声音生成AI等）下，根据给定条件生成相应内容。
2. **Autoregressive Generation（AR）策略**
    - **原理与应用**：按顺序逐个生成基本单位，在文字生成上非常成功，如语言模型根据前文依次生成后续内容。也可应用于影像（如Image GPT）和声音（如WavNet）生成，但本质上需要按部就班。
3. **Non - autoregressive Generation（NAR）策略**
    - **原理与特点**：可平行运算，一次生成所有基本单位，速度上有优势，但生成质量存在问题。。
4. **Autoregressive与Non - autoregressive结合策略**
    - **结合方式与优势**：先用Autoregressive生成精简版本，再用Non - autoregressive生成精细版本。
5. **Speculative Decoding优化策略**
    - **原理与速度提升**：通过引入预言家（可由快速但可能犯错的模型如Non - autoregressive Model或Compressive Model担任）来预判语言模型接下来会说的内容，从而提高生成速度。也可采用多个预言家来提高预测准确性。
# vision
#
1. **影像处理基础**
    - **影像构成**：图片由像素构成，影片由一帧一帧图片构成。
    - **人工智能对影像的处理**：通过编码器（Encoder）和解码器（Decoder）处理。
2. **生成策略**
- **以文字为条件**：如Sora模型，可根据文字描述生成动画场景、影片等。
     - **生成方式**：以文字生图为例，模型（如Transformer）会对文字进行处理，生成图片的各个部分（如将“一只在奔跑的狗”拆分为多个部分平行生成，最终组合）等。
    - **影像生影像**：包括影片完成（如生成连续的帧）、风格转换、画质提升等，可通过ControlNet等技术实现。
    - **其他输入生影像**：如Talking Head，可根据上传的参考图像生成相关影像。
3. **评估方法**：使用CLIP等工具评估影像生成的好坏，根据生成影像与文字描述的匹配程度等给予评分。
4. **面临挑战**
    - **文字生影片挑战**：计算量极其巨大。
    - **脑补问题**：生成影像时模型可能脑补过多导致结果不确定。
5. **互动性探索**：如Genie项目尝试实现与生成影像的更强互动，可收集大量游戏影片作为训练资料，从之前游戏画面抽取信息预测下一个画面及动作。


# 代码注释
#
## Chapter 1:Understanding Large Language Models


importlib库：
os库：
urllib库：
以下是对`importlib`、`os`和`urllib`库的介绍：

**一、`importlib`库**

`importlib`库提供了实现 Python 的导入机制的功能。主要包含以下一些重要的功能和对象：

1. `import_module()`函数：
   - 用于动态导入模块。可以接受模块名称作为字符串参数，并返回对应的模块对象。
   - 例如：`importlib.import_module('math')`可以导入`math`模块。

2. 与加载包相关的工具：
   - 可用于在运行时加载和操作 Python 包和模块，对于实现动态导入和插件系统非常有用。

**二、`os`库**

`os`库提供了一种与操作系统交互的方式，涵盖了众多与文件系统、进程管理等相关的功能。主要内容包括：

1. 文件和目录操作：
   - `os.listdir()`：列出指定目录下的所有文件和目录。
   - `os.mkdir()`：创建新目录。
   - `os.rename()`：重命名文件或目录。
   - `os.remove()`：删除文件。
   - `os.rmdir()`：删除空目录。

2. 路径操作：
   - `os.path.join()`：将多个路径片段组合成一个完整路径。
   - `os.path.exists()`：检查路径是否存在。
   - `os.path.isfile()`：判断路径是否是一个文件。
   - `os.path.isdir()`：判断路径是否是一个目录。

3. 进程管理：
   - `os.system()`：执行系统命令。
   - `os.getpid()`：获取当前进程的 ID。
   - `os.getcwd()`：获取当前工作目录。

**三、`urllib`库**

`urllib`库用于处理 URL 和进行网络请求。主要组成部分有：

1. `urllib.request`模块：
   - `urlopen()`函数：用于打开 URL 并获取响应。可以用来获取网页内容、下载文件等。
   - `Request`类：用于创建自定义的请求对象，可以设置请求头、方法等。

2. `urllib.parse`模块：
   - 用于解析和处理 URL。
   - 函数如`urlparse()`、`urlunparse()`、`quote()`、`unquote()`等，用于拆分、组合 URL 和对 URL 中的特殊字符进行编码和解码。

3. `urllib.error`模块：
   - 定义了在使用`urllib`进行网络请求时可能出现的错误类型。
   - 例如`URLError`和`HTTPError`，可以用于捕获和处理网络请求中的错误。


##
## Chapter 2:working with text
~~~
from importlib.metadata import version  # 从importlib.metadata模块中导入version函数，用于获取已安装包的版本信息
print("torch version:", version("torch"))  
print("tiktoken version:", version("tiktoken"))
import os  # 导入操作系统相关的功能模块
import urllib.request  # 导入用于处理URL请求的模块
# 检查当前目录下是否不存在名为"the-verdict.txt"的文件
if not os.path.exists("the-verdict.txt"):  
    # 定义要下载文件的URL地址，这里是从GitHub上的特定仓库获取一个文本
    url = ("https://raw.githubusercontent.com/rasbt/"
           "LLMs-from-scratch/main/ch02/01_main-chapter-code/"
           "the-verdict.txt")  
    # 定义下载后文件在本地保存的路径和文件名
    file_path = "the-verdict.txt"  
    # 使用urllib.request模块的urlretrieve函数从指定URL下载文件并保存到本地路径
    urllib.request.urlretrieve(url, file_path)  
    # 以只读模式（"r"）打开名为"the-verdict.txt"的文件，并使用UTF-8编码
~~~

~~~
with open("the-verdict.txt", "r", encoding="utf-8") as f:  
    # 读取文件的全部内容并存储在raw_text变量中
    raw_text = f.read()  

# 打印文件中字符的总数，通过计算raw_text字符串的长度得到
print("Total number of character:", len(raw_text))  
# 打印文件内容的前99个字符，用于查看文件的开头部分
print(raw_text[:99])
~~~
~~~
import re  # 导入正则表达式模块

# 使用re.split函数按照指定的正则表达式模式分割字符串text
# 正则表达式模式r'([,.]|\s)'表示匹配逗号、句号或者空白字符（空格、制表符、换行符等）
# 并且将匹配到的字符作为分割后的元素包含在结果列表中
result = re.split(r'([,.]|\s)', text)  

# 打印分割后的结果列表
print(result)  
# 列表推导式，遍历result列表中的每个元素item
# 对于每个item，先使用strip方法去除首尾的空白字符（包括空格、制表符、换行符等）
# 然后通过if item.strip()条件判断，只有当去除空白字符后的item不为空字符串时，才将其保留在新的列表中
result = [item for item in result if item.strip()]  
# 打印处理后的result列表
print(result)  
~~~

~~~
import re  # 导入正则表达式模块，用于进行复杂的字符串操作

text = "Hello, world. Is this-- a test?"  # 定义一个测试字符串

# 使用re.split函数按照指定的正则表达式模式分割字符串text
# 正则表达式模式r'([,.:;?_!"()\']|--|\s)'表示匹配以下任意一种字符或字符组合：
# 逗号、句号、冒号、分号、问号、下划线、双引号、单引号、括号（圆括号和方括号）、破折号（--）以及空白字符（\s，包括空格、制表符、换行符等）
# 并且将匹配到的字符或字符组合作为分割后的元素包含在结果列表中
result = re.split(r'([,.:;?_!"()\']|--|\s)', text)  

# 列表推导式，遍历result列表中的每个元素item
# 对于每个item，先使用strip方法去除首尾的空白字符（包括空格、制表符、换行符等）
# 然后通过if item.strip()条件判断，只有当去除空白字符后的item不为空字符串时，才将其保留在新的列表中
result = [item.strip() for item in result if item.strip()]  

# 打印处理后的result列表
print(result)  
~~~
~~~
import re  # 导入正则表达式模块

# 使用re.split函数按照指定的正则表达式模式分割原始文本raw_text
# 正则表达式模式r'([,.:;?_!"()\']|--|\s)'表示匹配逗号、句号、冒号、分号、问号、下划线、双引号、单引号、括号（圆括号和方括号）、破折号（--）以及空白字符（\s，包含空格、制表符、换行符等）
# 并且将匹配到的字符或字符组合作为分割后的元素包含在结果列表中
preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', raw_text)  

# 列表推导式，遍历preprocessed列表中的每个元素item
# 对于每个item，先使用strip方法去除首尾的空白字符（包括空格、制表符、换行符等）
# 然后通过if item.strip()条件判断，只有当去除空白字符后的item不为空字符串时，才将其保留在新的列表中
preprocessed = [item.strip() for item in preprocessed if item.strip()]  

# 打印处理后的preprocessed列表的前30个元素，用于查看部分处理后的文本内容
print(preprocessed[:30])  
print(len(preprocessed))  
all_words = sorted(set(preprocessed))  

# 计算排序后的单词列表all_words的长度，即词汇表的大小（不重复单词的数量）
vocab_size = len(all_words)  

# 打印词汇表的大小
print(vocab_size)  
~~~
~~~
# 使用字典推导式创建一个字典vocab
# 对于排序后的单词列表all_words中的每个单词token及其对应的索引integer（通过enumerate函数获取）
# 将单词token作为字典的键，索引integer作为字典的值
vocab = {token: integer for integer, token in enumerate(all_words)}  
# 使用enumerate函数遍历词汇表字典vocab的键值对（items），同时获取每个键值对的索引i和对应的元组item（包含单词和其索引）
for i, item in enumerate(vocab.items()):  
    print(item)  # 打印当前的键值对（单词和其索引）
    if i >= 50:  # 如果索引i大于等于50
        break  # 则停止循环，即只打印前51个键值对（因为索引从0开始）
~~~
~~~
import re


class SimpleTokenizerV1:
    def __init__(self, vocab):
        self.str_to_int = vocab
        # 创建一个从字符串到整数的映射字典。
        self.int_to_str = {i:s for s,i in vocab.items()}
        # 创建一个从整数到字符串的反向映射字典。
    def encode(self, text):
        preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', text)
        # 使用正则表达式将输入文本分割成单词和标点符号的列表。
        preprocessed = [
            item.strip() for item in preprocessed if item.strip()
        ]
        # 去除列表中每个元素的空白，并过滤掉空字符串。
        ids = [self.str_to_int[s] for s in preprocessed]
        # 将每个处理后的字符串转换为对应的整数 ID，使用之前创建的映射字典。
        return ids
        # 返回编码后的整数列表。
    def decode(self, ids):
        text = " ".join([self.int_to_str[i] for i in ids])
        # 将整数列表解码为字符串，使用反向映射字典，并在每个元素之间添加空格。
        # Replace spaces before the specified punctuations
        text = re.sub(r'\s+([,.?!"()\'])', r'\1', text)
        # 使用正则表达式将字符串中在指定标点符号前的多余空格替换为标点符号本身。
        return text
        # 返回解码后的文本。
~~~
~~~
# 创建SimpleTokenizerV1类的实例，传入之前构建的词汇表vocab
tokenizer = SimpleTokenizerV1(vocab)  

text = """"It's the last he painted, you know," 
           Mrs. Gisburn said with pardonable pride."""  # 定义要编码的文本

# 使用创建的tokenizer实例的encode方法对文本进行编码，将文本转换为整数列表
ids = tokenizer.encode(text)  

# 打印编码后的整数列表
print(ids)  
tokenizer.decode(ids)  # 使用之前创建的tokenizer对象的decode方法，将编码后的整数列表ids转换回原始文本格式。
tokenizer.decode(tokenizer.encode(text))  
# 首先使用tokenizer的encode方法对text文本进行编码，将文本转换为整数列表。
# 然后立即使用tokenizer的decode方法对刚刚得到的整数列表进行解码，将其转换回文本格式。

~~~
~~~
# 对预处理后的文本列表preprocessed进行操作，先将其转换为集合以去除重复元素，再转换回列表，最后进行排序
all_tokens = sorted(list(set(preprocessed)))  

# 向排序后的单词列表all_tokens中添加两个特殊标记："<|endoftext|>"和"<|unk|>"，表示文本结束和未知单词
all_tokens.extend(["<|endoftext|>", "<|unk|>"])  

# 使用字典推导式创建一个新的词汇表字典vocab，将单词token作为键，其对应的索引integer作为值
vocab = {token: integer for integer, token in enumerate(all_tokens)}  

# 计算词汇表字典vocab的键值对数量（即词汇表大小），但这行代码没有将结果赋值给变量或进行其他操作，可能是用于查看词汇表大小
len(vocab.items())  

# 遍历词汇表字典vocab的最后5个键值对，获取每个键值对的索引i和对应的元组item（包含单词和其索引）
for i, item in enumerate(list(vocab.items())[-5:]):  
    print(item)  # 打印当前的键值对（单词和其索引）
import re  # 导入正则表达式模块，用于文本分割和格式化
class SimpleTokenizerV2:
    def __init__(self, vocab):
        """
        构造函数，用于初始化分词器
        参数:
            vocab (dict): 词汇表，字典类型，键为字符串（词汇），值为整数（词汇ID）。
        """
        self.str_to_int = vocab  # 字符串到整数的映射，即词汇到词汇ID的映射
        self.int_to_str = {i: s for s, i in vocab.items()}  # 整数到字符串的映射，即词汇ID到词汇的映射

    def encode(self, text):
        """
        将输入文本编码为词汇ID列表。
        
        参数:
            text (str): 输入文本。
        
        返回:
            list: 编码后的词汇ID列表。
        """
        # 使用正则表达式分割文本，保留分隔符（如标点符号、空格等）
        preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', text)
        # 去除空字符串项，并去除字符串两端的空白字符
        preprocessed = [item.strip() for item in preprocessed if item.strip()]
        # 对于不在词汇表中的词汇，用"<|unk|>"代替，表示未知词汇
        preprocessed = [item if item in self.str_to_int else "<|unk|>" for item in preprocessed]
        # 将处理后的词汇列表转换为词汇ID列表
        ids = [self.str_to_int[s] for s in preprocessed]
        return ids
    def decode(self, ids):
        """
        将词汇ID列表解码为文本。
        参数:
            ids (list): 词汇ID列表。
        返回:
            str: 解码后的文本。
        """
        # 将词汇ID列表转换为词汇列表，然后连接成字符串
        text = " ".join([self.int_to_str[i] for i in ids])
        # 使用正则表达式替换空格和指定标点符号之间的空格，以格式化输出文本
        # 例如，将" hello ,"转换为"hello,"
        text = re.sub(r'\s+([,.:;?!"()\'])', r'\1', text)
        # 注意：这里可能还需要处理"<|unk|>"的显示格式，或者进行其他文本格式化操作
        # 但根据当前代码，直接返回格式化后的文本
        return text
~~~
~~~
# 创建SimpleTokenizerV2类的实例
tokenizer = SimpleTokenizerV2(vocab)  
text1 = "Hello, do you like tea?"  # 定义第一个文本
text2 = "In the sunlit terraces of the palace."  # 定义第二个文本
# 使用<|endoftext|>作为分隔符将text1和text2连接成一个新的文本
text = " <|endoftext|> ".join((text1, text2))  

print(text)  # 打印连接后的文本

# 使用创建的tokenizer实例的encode方法对连接后的文本text进行编码，将文本转换为整数列表，但这行代码没有保存编码结果
tokenizer.encode(text)  

# 先使用tokenizer的encode方法对text文本进行编码，再使用tokenizer的decode方法对编码结果进行解码，将其转换回文本格式，最后打印解码后的文本
tokenizer.decode(tokenizer.encode(text))  
import importlib
import tiktoken

# 使用importlib.metadata.version函数获取并打印tiktoken库的版本号
print("tiktoken version:", importlib.metadata.version("tiktoken"))  

# 使用tiktoken库的get_encoding函数获取"gpt2"编码的tokenizer对象
tokenizer = tiktoken.get_encoding("gpt2")  

text = (
    "Hello, do you like tea? <|endoftext|> In the sunlit terraces"
     "of someunknownPlace."
)  # 定义包含文本和特殊标记<|endoftext|>的字符串

# 使用获取的tokenizer对象的encode方法对文本进行编码，将文本转换为整数列表
# 同时指定allowed_special参数为{"<|endoftext|>"}，表示允许处理这个特殊标记
integers = tokenizer.encode(text, allowed_special={"<|endoftext|>"})  

print(integers)  # 打印编码后的整数列表

# 使用tokenizer对象的decode方法对编码后的整数列表进行解码，将其转换回文本格式
strings = tokenizer.decode(integers)  

print(strings)  # 打印解码后的文本
~~~
~~~
with open("the-verdict.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()
# 打开名为"the-verdict.txt"的文件，以只读模式（"r"）读取其中的内容，并使用 UTF-8 编码。将读取的内容存储在 raw_text 变量中。

enc_text = tokenizer.encode(raw_text)
print(len(enc_text))
# 使用之前创建的 tokenizer 对象对 raw_text 进行编码，得到一个整数列表 enc_text。然后打印这个列表的长度，即文本编码后的长度。

enc_sample = enc_text[50:]
# 获取编码后的列表 enc_text 从索引 50 开始的部分，存储在 enc_sample 变量中。

context_size = 4
# 设置上下文大小为 4。

x = enc_sample[:context_size]
y = enc_sample[1:context_size + 1]
# 分别从 enc_sample 中获取不同范围的子列表，x 是前 context_size 个元素，y 是从第二个元素开始到 context_size + 1 个元素。

print(f"x: {x}")
print(f"y:      {y}")
# 打印 x 和 y 的值。

for i in range(1, context_size + 1):
    context = enc_sample[:i]
    desired = enc_sample[i]
    # 在循环中，每次从 enc_sample 中获取不同长度的上下文和下一个期望的元素。

    print(context, "---->", desired)
# 打印上下文和期望的元素。

for i in range(1, context_size + 1):
    context = enc_sample[:i]
    desired = enc_sample[i]
    # 再次在循环中获取上下文和期望的元素。

    print(tokenizer.decode(context), "---->", tokenizer.decode([desired]))
# 打印解码后的上下文和下一个期望的元素的解码结果。

import torch
print("PyTorch version:", torch.__version__)
# 导入 PyTorch 库，并打印其版本号。
~~~
~~~
from torch.utils.data import Dataset, DataLoader
# 导入 PyTorch 中的 Dataset 和 DataLoader 类，用于创建自定义数据集和数据加载器。

class GPTDatasetV1(Dataset):
    def __init__(self, txt, tokenizer, max_length, stride):
     
        txt (str)：要处理的文本内容。
        tokenizer：用于将文本编码为整数序列的对象。
        max_length (int)：每个输入序列的最大长度。
        stride (int)：滑动窗口的步长，用于确定相邻序列之间的重叠程度。
        初始化实例变量：
        self.input_ids (list)：存储输入序列的张量列表。
        self.target_ids (list)：存储目标序列的张量列表。
        self.input_ids = []
        self.target_ids = []
        token_ids = tokenizer.encode(txt, allowed_special={"<|endoftext|>"})
        # Use a sliding window to chunk the book into overlapping sequences of max_length
        for i in range(0, len(token_ids) - max_length, stride):
            input_chunk = token_ids[i:i + max_length]
            target_chunk = token_ids[i + 1: i + max_length + 1]
            self.input_ids.append(torch.tensor(input_chunk))
            self.target_ids.append(torch.tensor(target_chunk))

    def __len__(self):
       # 返回数据集的长度，即输入序列的数量。
        return len(self.input_ids)
    def __getitem__(self, idx):
        """
        根据索引返回数据集中的一个样本，即一个输入序列和对应的目标序列。
        参数：
        idx (int)：样本的索引。
        返回：
        tuple：包含输入序列张量和目标序列张量的元组。
        """
        return self.input_ids[idx], self.target_ids[idx]
def create_dataloader_v1(txt, batch_size=4, max_length=256, 
                         stride=128, shuffle=True, drop_last=True,
                         num_workers=0):
    """
    创建数据加载器的函数。

    参数：
    txt (str)：要处理的文本内容。
    batch_size (int)：每个批次中的样本数量，默认为 4。
    max_length (int)：每个输入序列的最大长度，默认为 256。
    stride (int)：滑动窗口的步长，默认为 128。
    shuffle (bool)：是否打乱数据集，默认为 True。
    drop_last (bool)：是否丢弃最后一个不完整的批次，默认为 True。
    num_workers (int)：用于数据加载的工作进程数量，默认为 0。
    返回：
    DataLoader：创建的数据加载器
    tokenizer = tiktoken.get_encoding("gpt2")
    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)
    # Create dataloader
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        drop_last=drop_last,
        num_workers=num_workers
    )

    return dataloader

with open("the-verdict.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()
dataloader = create_dataloader_v1(
    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False
)
# 使用 create_dataloader_v1 函数创建一个数据加载器，传入 raw_text 和特定的参数配置。
data_iter = iter(dataloader)
first_batch = next(data_iter)
print(first_batch)
# 创建一个迭代器 data_iter，用于遍历数据加载器中的批次。获取迭代器中的下一个元素，即第一个批次，并打印它。
second_batch = next(data_iter)
print(second_batch)
# 再次获取迭代器中的下一个元素，即第二个批次，并打印它。
dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)
# 创建另一个数据加载器，使用不同的批次大小和步长参数。
data_iter = iter(dataloader)
inputs, targets = next(data_iter)
print("Inputs:\n", inputs)
print("\nTargets:\n", targets)
# 获取新数据加载器中的下一个元素，解包为输入序列和目标序列。分别打印输入序列和目标序列。
~~~
~~~
import torch

input_ids = torch.tensor([2, 3, 5, 1])
vocab_size = 6
output_dim = 3
torch.manual_seed(123)
# 设置随机种子以确保可重复性。
embedding_layer = torch.nn.Embedding(vocab_size, output_dim)
# 创建一个嵌入层（Embedding layer），它将输入的整数索引（代表词汇表中的单词）映射到一个固定长度的向量表示。
# 参数 vocab_size 表示词汇表的大小，output_dim 表示每个单词的嵌入向量的维度。
print(embedding_layer.weight)
# 打印嵌入层的权重矩阵，这个矩阵的形状是 (vocab_size, output_dim)，每一行代表词汇表中一个单词的嵌入向量。
print(embedding_layer(torch.tensor([3])))
# 将单个整数索引 3 传入嵌入层，得到对应的嵌入向量，并打印出来。
print(embedding_layer(input_ids))
# 将输入的整数索引张量 input_ids 传入嵌入层，得到对应的嵌入向量张量，并打印出来。每个整数索引对应一个嵌入向量，所以输出的张量形状是 (input_ids 的长度, output_dim)。
~~~
~~~
vocab_size = 50257
output_dim = 256
# 设置词汇表大小和输出维度。
token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)
# 创建一个嵌入层用于将词汇表中的整数索引（代表单词）映射到一个长度为 output_dim 的向量。
max_length = 4
dataloader = create_dataloader_v1(
    raw_text, batch_size=8, max_length=max_length,
    stride=max_length, shuffle=False
)
# 使用之前定义的函数创建一个数据加载器，传入原始文本 raw_text 和一些参数，包括批次大小为 8、最大序列长度为 max_length、步长为 max_length 且不打乱数据。
data_iter = iter(dataloader)
inputs, targets = next(data_iter)
print("Token IDs:\n", inputs)
print("\nInputs shape:\n", inputs.shape)
# 从数据加载器中获取下一个批次的输入和目标，打印输入的整数索引（代表单词）和输入的形状。
token_embeddings = token_embedding_layer(inputs)
print(token_embeddings.shape)
# 使用嵌入层将输入的整数索引转换为对应的嵌入向量，打印嵌入向量的形状。
context_length = max_length
pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)
pos_embeddings = pos_embedding_layer(torch.arange(max_length))
print(pos_embeddings.shape)
# 创建一个位置嵌入层，用于给每个位置分配一个长度为 output_dim 的向量。然后使用 torch.arange 创建一个从 0 到 max_length - 1 的整数序列，传入位置嵌入层得到位置嵌入向量，并打印其形状。
input_embeddings = token_embeddings + pos_embeddings
print(input_embeddings.shape)
# 将单词的嵌入向量和位置嵌入向量相加，得到最终的输入嵌入向量，并打印其形状。
~~~
##
## Chapter 3
~~~
from importlib.metadata import version。
print("torch version:", version("torch"))
import torch
inputs = torch.tensor(
  [[0.43, 0.15, 0.89],  # Your     (x^1)
   [0.55, 0.87, 0.66],  # journey  (x^2)
   [0.57, 0.85, 0.64],  # starts   (x^3)
   [0.22, 0.58, 0.33],  # with     (x^4)
   [0.77, 0.25, 0.10],  # one      (x^5)
   [0.05, 0.80, 0.55]]  # step     (x^6)
)
query = inputs[1]  
attn_scores_2 = torch.empty(inputs.shape[0])
# 创建一个形状为 (6,) 的空张量，用于存储注意力分数。
for i, x_i in enumerate(inputs):
    attn_scores_2[i] = torch.dot(x_i, query)  # dot product (transpose not necessary here since they are 1-dim vectors)
# 通过遍历输入张量中的每个向量，与查询向量进行点积运算，将结果存储在 attn_scores_2 张量中。
print(attn_scores_2)
# 打印计算得到的注意力分数张量。
~~~
~~~
res = 0.
# 初始化变量 res 为 0.0。
for idx, element in enumerate(inputs[0]):
    res += inputs[0][idx] * query[idx]
print(res)
print(torch.dot(inputs[0], query))
# 使用 PyTorch 的 dot 函数再次计算第一个输入向量与查询向量的点积，验证手动计算的正确性。
attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()
# 将之前计算得到的注意力分数 attn_scores_2 进行归一化处理，通过除以它们的总和，得到注意力权重 attn_weights_2_tmp。
print("Attention weights:", attn_weights_2_tmp)
# 打印归一化后的注意力权重。
print("Sum:", attn_weights_2_tmp.sum())
# 打印注意力权重的总和，应该接近 1.0，因为归一化后的权重总和应该为 1。
~~~
~~~
def softmax_naive(x):
    """
    定义一个简单的 softmax 函数。
    参数
    x (torch.Tensor)：输入张量。
    返回：
    torch.Tensor：经过 softmax 处理后的张量。
    ""
    return torch.exp(x) / torch.exp(x).sum(dim=0)
attn_weights_2_naive = softmax_naive(attn_scores_2)
# 使用自定义的 softmax_naive 函数对注意力分数 attn_scores_2 进行 softmax 处理，得到注意力权重 attn_weights_2_naive。
print("Attention weights:", attn_weights_2_naive)
print("Sum:", attn_weights_2_naive.sum())
# 打印自定义 softmax 处理后的注意力权重和它们的总和，总和应该接近 1.0。
attn_weights_2 = torch.softmax(attn_scores_2, dim=0)
# 使用 PyTorch 内置的 softmax 函数对注意力分数 attn_scores_2 进行 softmax 处理，指定在第一个维度上进行 softmax。
print("Attention weights:", attn_weights_2)
print("Sum:", attn_weights_2.sum())
# 打印内置 softmax 处理后的注意力权重和它们的总和，总和应该接近 1.0。
~~~
~~~
query = inputs[1]  # 2nd input token is the query
# 重新将输入张量中的第二个向量定义为查询向量。
context_vec_2 = torch.zeros(query.shape)
# 创建一个形状与查询向量相同的全零张量，用于存储上下文向量。
for i, x_i in enumerate(inputs):
    context_vec_2 += attn_weights_2[i] * x_i
# 遍历输入张量中的每个向量，将每个向量乘以对应的注意力权重，然后累加到上下文向量中。
print(context_vec_2)
# 打印计算得到的上下文向量。
~~~

~~~
attn_scores = torch.empty(6, 6)
for i, x_i in enumerate(inputs):
    for j, x_j in enumerate(inputs):
        attn_scores[i, j] = torch.dot(x_i, x_j)
# 通过双重循环，计算输入张量中每对向量的点积，将结果存储在 attn_scores 张量中。
print(attn_scores)
# 打印手动计算的注意力分数张量。
attn_scores = inputs @ inputs.T
# 使用矩阵乘法计算输入张量与自身的转置的乘积，得到注意力分数张量，这是一种更简洁的计算方式。
print(attn_scores)
# 打印矩阵乘法计算得到的注意力分数张量。
attn_weights = torch.softmax(attn_scores, dim=-1)
# 对注意力分数张量在最后一个维度上进行 softmax 处理，得到注意力权重张量。
print(attn_weights)
# 打印注意力权重张量。
row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])
print("Row 2 sum:", row_2_sum)
# 手动计算并打印第二行注意力权重的总和。
print("All row sums:", attn_weights.sum(dim=-1))
# 打印所有行的注意力权重总和，应该都接近 1.0。
all_context_vecs = attn_weights @ inputs
# 使用注意力权重张量与输入张量进行矩阵乘法，得到所有上下文向量的张量。
print(all_context_vecs)
# 打印所有上下文向量的张量。
print("Previous 2nd context vector:", context_vec_2)
# 打印之前计算的第二个上下文向量，用于比较。
~~~

~~~
x_2 = inputs[1]  # second input element
# 选择输入张量中的第二个元素作为特定的输入向量 x_2。
d_in = inputs.shape[1]  # the input embedding size, d=3
d_out = 2  # the output embedding size, d=2
# 确定输入向量的维度 d_in 和输出向量的维度 d_out。
torch.manual_seed(123)
# 设置随机种子以确保可重复性。
W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)
W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)
W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)
# 创建三个可训练参数张量 W_query、W_key 和 W_value，分别用于查询、键和值的线性变换，初始化为随机值且设置为不需要梯度更新。
query_2 = x_2 @ W_query  # _2 because it's with respect to the 2nd input element
key_2 = x_2 @ W_key
value_2 = x_2 @ W_value
# 使用选定的输入向量 x_2 与相应的参数张量进行矩阵乘法，得到查询向量 query_2、键向量 key_2 和值向量 value_2。
print(query_2)
# 打印查询向量 query_2。
keys = inputs @ W_key
values = inputs @ W_value
# 使用输入张量与参数张量 W_key 和 W_value 进行矩阵乘法，得到所有输入向量对应的键向量和值向量的张量。
print("keys.shape:", keys.shape)
print("values.shape:", values.shape)
# 打印键向量和值向量张量的形状。
keys_2 = keys[1]  # Python starts index at 0
# 选择键向量张量中的第二个向量，对应于输入张量中的第二个元素。
attn_score_22 = query_2.dot(keys_2)
print(attn_score_22)
# 计算查询向量 query_2 与选定的键向量 keys_2 的点积，得到特定的注意力分数 attn_score_22，并打印结果。
attn_scores_2 = query_2 @ keys.T  # All attention scores for given query
print(attn_scores_2)
# 使用查询向量 query_2 与键向量张量的转置进行矩阵乘法，得到所有注意力分数的张量 attn_scores_2，并打印结果。
d_k = keys.shape[1]
attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)
print(attn_weights_2)
# 计算键向量的维度 d_k，对注意力分数张量 attn_scores_2 进行缩放并在最后一个维度上进行 softmax 处理，得到注意力权重张量 attn_weights_2，并打印结果。
context_vec_2 = attn_weights_2 @ values
print(context_vec_2)
# 使用注意力权重张量 attn_weights_2 与值向量张量进行矩阵乘法，得到上下文向量 context_vec_2，并打印结果。
~~~
~~~
import torch.nn as nn
# 导入 PyTorch 的神经网络模块。

class SelfAttention_v1(nn.Module):
    def __init__(self, d_in, d_out):
        super().__init__()
        # 调用父类（nn.Module）的初始化方法。

        self.W_query = nn.Parameter(torch.rand(d_in, d_out))
        self.W_key = nn.Parameter(torch.rand(d_in, d_out))
        self.W_value = nn.Parameter(torch.rand(d_in, d_out))
        # 创建三个可训练的参数张量，分别用于查询（query）、键（key）和值（value）的线性变换，初始化为随机值。

    def forward(self, x):
        keys = x @ self.W_key
        queries = x @ self.W_query
        values = x @ self.W_value
        # 使用输入张量 x 与相应的参数张量进行矩阵乘法，得到键、查询和值向量。

        attn_scores = queries @ keys.T  # omega
        attn_weights = torch.softmax(
            attn_scores / keys.shape[-1]**0.5, dim=-1
        )
        # 计算查询向量和键向量的乘积得到注意力分数，然后对注意力分数进行缩放并在最后一个维度上进行 softmax 处理，得到注意力权重。

        context_vec = attn_weights @ values
        return context_vec
        # 使用注意力权重与值向量进行矩阵乘法，得到上下文向量并返回。

torch.manual_seed(123)
sa_v1 = SelfAttention_v1(d_in, d_out)
print(sa_v1(inputs))
# 设置随机种子，创建 SelfAttention_v1 类的实例，并将输入张量传入实例的 forward 方法，打印输出的上下文向量。

class SelfAttention_v2(nn.Module):
    def __init__(self, d_in, d_out, qkv_bias=False):
        super().__init__()
        # 调用父类（nn.Module）的初始化方法。

        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)
        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)
        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)
        # 创建三个线性层，分别用于查询、键和值的线性变换，可以选择是否包含偏置项。

    def forward(self, x):
        keys = self.W_key(x)
        queries = self.W_query(x)
        values = self.W_value(x)
        # 使用输入张量 x 传入线性层，得到键、查询和值向量。

        attn_scores = queries @ keys.T
        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)
        # 计算查询向量和键向量的乘积得到注意力分数，然后对注意力分数进行缩放并在最后一个维度上进行 softmax 处理，得到注意力权重。

        context_vec = attn_weights @ values
        return context_vec
        # 使用注意力权重与值向量进行矩阵乘法，得到上下文向量并返回。

torch.manual_seed(789)
sa_v2 = SelfAttention_v2(d_in, d_out)
print(sa_v2(inputs))
# 设置不同的随机种子，创建 SelfAttention_v2 类的实例，并将输入张量传入实例的 forward 方法，打印输出的上下文向量。
~~~
~~~
# Reuse the query and key weight matrices of the
# SelfAttention_v2 object from the previous section for convenience
queries = sa_v2.W_query(inputs)
keys = sa_v2.W_key(inputs)
attn_scores = queries @ keys.T
# 重新使用之前创建的 SelfAttention_v2 对象的查询和键的权重矩阵来计算注意力分数。

attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)
print(attn_weights)
# 对注意力分数进行 softmax 处理得到注意力权重并打印。

context_length = attn_scores.shape[0]
mask_simple = torch.tril(torch.ones(context_length, context_length))
print(mask_simple)
# 创建一个下三角矩阵作为简单的掩码，打印该掩码。

masked_simple = attn_weights*mask_simple
print(masked_simple)
# 将注意力权重与掩码相乘得到掩码后的权重并打印。

row_sums = masked_simple.sum(dim=-1, keepdim=True)
masked_simple_norm = masked_simple / row_sums
print(masked_simple_norm)
# 计算掩码后权重的行总和，并将掩码后的权重除以行总和进行归一化，打印归一化后的结果。

mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)
masked = attn_scores.masked_fill(mask.bool(), -torch.inf)
print(masked)
# 创建一个上三角矩阵作为掩码，并将注意力分数中对应掩码位置的值设为负无穷，打印掩码后的注意力分数。

attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)
print(attn_weights)
# 对掩码后的注意力分数进行 softmax 处理得到新的注意力权重并打印。

torch.manual_seed(123)
dropout = torch.nn.Dropout(0.5)  # dropout rate of 50%
example = torch.ones(6, 6)  # create a matrix of ones
print(dropout(example))
# 设置随机种子，创建一个 dropout 层，将一个全为 1 的矩阵传入 dropout 层并打印结果。

torch.manual_seed(123)
print(dropout(attn_weights))
# 再次设置相同的随机种子，将注意力权重传入 dropout 层并打印结果。

batch = torch.stack((inputs, inputs), dim=0)
print(batch.shape)  # 2 inputs with 6 tokens each, and each token has a certain dimension
# 将两个输入张量堆叠在一起形成一个批次，打印批次的形状。
~~~
~~~
class CausalAttention(nn.Module):
    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):
        super().__init__()
        # 调用父类（nn.Module）的初始化方法。

        self.d_out = d_out
        # 存储输出维度。

        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)
        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)
        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)
        # 创建三个线性层用于查询、键和值的线性变换，可以选择是否包含偏置项。

        self.dropout = nn.Dropout(dropout)
        # 创建一个 dropout 层，用于在训练过程中随机丢弃一些神经元，防止过拟合。

        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))
        # 创建一个上三角掩码，并将其注册为缓冲区，以便在模型的不同调用中保持不变。

    def forward(self, x):
        b, num_tokens, d_in = x.shape
        # 获取输入张量的形状信息，分别是批次大小 b、每个批次中的标记数量 num_tokens 和输入维度 d_in。

        keys = self.W_key(x)
        queries = self.W_query(x)
        values = self.W_value(x)
        # 使用输入张量 x 传入线性层，得到键、查询和值向量。

        attn_scores = queries @ keys.transpose(1, 2)
        # 计算查询向量和键向量的乘积得到注意力分数，这里的转置操作与之前的代码略有不同。

        attn_scores.masked_fill_(
            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)
        # 将注意力分数中对应上三角掩码位置的值设为负无穷，`:num_tokens` 是为了处理批次中标记数量小于支持的上下文长度的情况。

        attn_weights = torch.softmax(
            attn_scores / keys.shape[-1]**0.5, dim=-1
        )
        attn_weights = self.dropout(attn_weights)
        # 对注意力分数进行缩放并在最后一个维度上进行 softmax 处理得到注意力权重，然后将注意力权重传入 dropout 层。

        context_vec = attn_weights @ values
        return context_vec
        # 使用注意力权重与值向量进行矩阵乘法，得到上下文向量并返回。

torch.manual_seed(123)
context_length = batch.shape[1]
ca = CausalAttention(d_in, d_out, context_length, 0.0)
# 设置随机种子，获取批次张量的形状信息以确定上下文长度，创建 CausalAttention 类的实例，传入输入维度、输出维度、上下文长度和 dropout 率（这里为 0.0，表示不进行 dropout）。

context_vecs = ca(batch)
print(context_vecs)
print("context_vecs.shape:", context_vecs.shape)
# 将批次张量传入实例的 forward 方法，得到上下文向量并打印结果和形状。
~~~
~~~
class MultiHeadAttention(nn.Module):
    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):
        super().__init__()
        # 调用父类（nn.Module）的初始化方法。

        assert (d_out % num_heads == 0), "d_out must be divisible by num_heads"
        # 断言输出维度 d_out 必须能被头的数量 num_heads 整除。

        self.d_out = d_out
        # 存储输出维度。

        self.num_heads = num_heads
        # 存储头的数量。

        self.head_dim = d_out // num_heads
        # 计算每个头的维度，即输出维度除以头的数量。

        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)
        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)
        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)
        # 创建三个线性层用于查询、键和值的线性变换，可以选择是否包含偏置项。

        self.out_proj = nn.Linear(d_out, d_out)
        # 创建一个线性层用于将多头的输出进行组合。

        self.dropout = nn.Dropout(dropout)
        # 创建一个 dropout 层，用于在训练过程中随机丢弃一些神经元，防止过拟合。

        self.register_buffer(
            "mask",
            torch.triu(torch.ones(context_length, context_length),
                       diagonal=1)
        )
        # 创建一个上三角掩码，并将其注册为缓冲区，以便在模型的不同调用中保持不变。

    def forward(self, x):
        b, num_tokens, d_in = x.shape
        # 获取输入张量的形状信息，分别是批次大小 b、每个批次中的标记数量 num_tokens 和输入维度 d_in。

        keys = self.W_key(x)
        queries = self.W_query(x)
        values = self.W_value(x)
        # 使用输入张量 x 传入线性层，得到键、查询和值向量。

        # We implicitly split the matrix by adding a `num_heads` dimension
        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)
        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)
        values = values.view(b, num_tokens, self.num_heads, self.head_dim)
        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)
        # 将键、查询和值向量的形状进行调整，增加一个头的维度，以便进行多头注意力计算。

        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)
        keys = keys.transpose(1, 2)
        queries = queries.transpose(1, 2)
        values = values.transpose(1, 2)
        # 对调整后的张量进行转置，以便进行注意力分数的计算。

        # Compute scaled dot-product attention (aka self-attention) with a causal mask
        attn_scores = queries @ keys.transpose(2, 3)
        # 计算查询向量和键向量的乘积得到注意力分数。

        # Original mask truncated to the number of tokens and converted to boolean
        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]
        # 将掩码截断到与输入张量中的标记数量相同，并转换为布尔类型。

        # Use the mask to fill attention scores
        attn_scores.masked_fill_(mask_bool, -torch.inf)
        # 将注意力分数中对应掩码位置的值设为负无穷。

        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)
        attn_weights = self.dropout(attn_weights)
        # 对注意力分数进行缩放并在最后一个维度上进行 softmax 处理得到注意力权重，然后将注意力权重传入 dropout 层。

        # Shape: (b, num_tokens, num_heads, head_dim)
        context_vec = (attn_weights @ values).transpose(1, 2)
        # 使用注意力权重与值向量进行矩阵乘法得到上下文向量，然后进行转置。

        # Combine heads, where self.d_out = self.num_heads * self.head_dim
        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)
        context_vec = self.out_proj(context_vec)
        # 将多头的上下文向量进行合并，并可以选择使用线性层进行进一步的投影。

        return context_vec
        # 返回上下文向量。

torch.manual_seed(123)
batch_size, context_length, d_in = batch.shape
d_out = 2
mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)
# 设置随机种子，获取批次张量的形状信息，创建 MultiHeadAttention 类的实例，传入输入维度、输出维度、上下文长度、dropout 率和头的数量。

context_vecs = mha(batch)
print(context_vecs)
print("context_vecs.shape:", context_vecs.shape)
# 将批次张量传入实例的 forward 方法，得到上下文向量并打印结果和形状。
~~~
~~~
# (b, num_heads, num_tokens, head_dim) = (1, 2, 3, 4)
a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],
                    [0.8993, 0.0390, 0.9268, 0.7388],
                    [0.7179, 0.7058, 0.9156, 0.4340]],

                   [[0.0772, 0.3565, 0.1479, 0.5331],
                    [0.4066, 0.2318, 0.4545, 0.9737],
                    [0.4606, 0.5159, 0.4220, 0.5786]]]])
# 创建一个四维张量 a，代表多头注意力机制中的键或查询张量，其中包含两个头，每个头有三个标记，每个标记的维度为 4。

print(a @ a.transpose(2, 3))
# 计算张量 a 与其转置的乘积，即计算多头注意力机制中的注意力分数。

first_head = a[0, 0, :, :]
first_res = first_head @ first_head.T
print("First head:\n", first_res)
# 选择张量 a 的第一个头，计算其与自身转置的乘积，得到第一个头的注意力分数，并打印结果。

second_head = a[0, 1, :, :]
second_res = second_head @ second_head.T
print("\nSecond head:\n", second_res)
# 选择张量 a 的第二个头，计算其与自身转置的乘积，得到第二个头的注意力分数，并打印结果。
~~~
## Chapter 4:working with text
~~~
from importlib.metadata import version

import matplotlib
import tiktoken
import torch

print("matplotlib version:", version("matplotlib"))
print("torch version:", version("torch"))
print("tiktoken version:", version("tiktoken"))
# 导入所需的模块和函数，然后分别打印 matplotlib、torch 和 tiktoken 的版本信息。

GPT_CONFIG_124M = {
    "vocab_size": 50257,    # Vocabulary size
    "context_length": 1024, # Context length
    "emb_dim": 768,         # Embedding dimension
    "n_heads": 12,          # Number of attention heads
    "n_layers": 12,         # Number of layers
    "drop_rate": 0.1,       # Dropout rate
    "qkv_bias": False       # Query-Key-Value bias
}
# 创建一个字典 GPT_CONFIG_124M，存储了一个类似于 GPT 模型的配置参数，包括词汇表大小、上下文长度、嵌入维度、注意力头的数量、层数、dropout 率和是否有 Query-Key-Value 偏置。
~~~
~~~
import torch
import torch.nn as nn
# 导入 PyTorch 和 PyTorch 的神经网络模块。

class DummyGPTModel(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        # 调用父类（nn.Module）的初始化方法。

        self.tok_emb = nn.Embedding(cfg["vocab_size"], cfg["emb_dim"])
        self.pos_emb = nn.Embedding(cfg["context_length"], cfg["emb_dim"])
        self.drop_emb = nn.Dropout(cfg["drop_rate"])
        # 创建一个词嵌入层（tok_emb）、一个位置嵌入层（pos_emb）和一个 dropout 层（drop_emb），使用配置字典中的参数进行初始化。

        # Use a placeholder for TransformerBlock
        self.trf_blocks = nn.Sequential(
            *[DummyTransformerBlock(cfg) for _ in range(cfg["n_layers"])])
        # 创建一个包含多个 DummyTransformerBlock 的序列，模拟 Transformer 的多个层。

        # Use a placeholder for LayerNorm
        self.final_norm = DummyLayerNorm(cfg["emb_dim"])
        # 创建一个模拟的 LayerNorm 层。

        self.out_head = nn.Linear(
            cfg["emb_dim"], cfg["vocab_size"], bias=False
        )
        # 创建一个线性层，将嵌入维度转换为词汇表大小，用于输出预测。

    def forward(self, in_idx):
        batch_size, seq_len = in_idx.shape
        tok_embeds = self.tok_emb(in_idx)
        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))
        x = tok_embeds + pos_embeds
        x = self.drop_emb(x)
        x = self.trf_blocks(x)
        x = self.final_norm(x)
        logits = self.out_head(x)
        return logits
        # 定义前向传播方法，接收输入索引张量，计算词嵌入和位置嵌入，将它们相加后经过 dropout、多个 Transformer 块、LayerNorm 和线性层，最终返回预测的 logits。

class DummyTransformerBlock(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        # 定义一个空的初始化方法，因为这个类只是一个占位符。

    def forward(self, x):
        # 这个块什么也不做，只是返回输入。
        return x

class DummyLayerNorm(nn.Module):
    def __init__(self, normalized_shape, eps=1e-5):
        super().__init__()
        # 定义一个空的初始化方法，参数只是为了模仿 LayerNorm 的接口。

    def forward(self, x):
        # 这个层什么也不做，只是返回输入。
        return x

import tiktoken
# 导入 tiktoken 库。

tokenizer = tiktoken.get_encoding("gpt2")
# 获取一个 GPT-2 的编码对象。

batch = []
# 创建一个空列表用于存储批次数据。

txt1 = "Every effort moves you"
txt2 = "Every day holds a"
# 定义两个文本字符串。

batch.append(torch.tensor(tokenizer.encode(txt1)))
batch.append(torch.tensor(tokenizer.encode(txt2)))
batch = torch.stack(batch, dim=0)
print(batch)
# 将两个文本编码为张量并添加到批次列表中，然后将批次列表转换为张量并打印。

torch.manual_seed(123)
model = DummyGPTModel(GPT_CONFIG_124M)
# 设置随机种子，创建 DummyGPTModel 类的实例，传入配置字典。

logits = model(batch)
print("Output shape:", logits.shape)
print(logits)
# 将批次张量传入模型实例的 forward 方法，得到预测的 logits，打印输出的形状和 logits。
~~~
~~~
torch.manual_seed(123)
# 设置随机种子以确保可重复性。

# create 2 training examples with 5 dimensions (features) each
batch_example = torch.randn(2, 5)
# 创建一个形状为 (2, 5) 的随机张量，代表两个训练样本，每个样本有 5 个特征。

layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())
out = layer(batch_example)
print(out)
# 创建一个由线性层和 ReLU 激活函数组成的序列模型，将训练样本传入模型得到输出，并打印输出结果。

mean = out.mean(dim=-1, keepdim=True)
var = out.var(dim=-1, keepdim=True)
# 计算输出张量在最后一个维度上的均值和方差。

print("Mean:\n", mean)
print("Variance:\n", var)
# 打印均值和方差。

out_norm = (out - mean) / torch.sqrt(var)
print("Normalized layer outputs:\n", out_norm)
# 对输出张量进行标准化，即减去均值并除以标准差，得到标准化后的输出，并打印结果。

mean = out_norm.mean(dim=-1, keepdim=True)
var = out_norm.var(dim=-1, keepdim=True)
print("Mean:\n", mean)
print("Variance:\n", var)
# 再次计算标准化后的输出张量的均值和方差，并打印结果。

torch.set_printoptions(sci_mode=False)
print("Mean:\n", mean)
print("Variance:\n", var)
# 设置 PyTorch 的打印选项，关闭科学计数法，再次打印均值和方差。

class LayerNorm(nn.Module):
    def __init__(self, emb_dim):
        super().__init__()
        self.eps = 1e-5
        self.scale = nn.Parameter(torch.ones(emb_dim))
        self.shift = nn.Parameter(torch.zeros(emb_dim))
        # 定义一个自定义的 LayerNorm 类，继承自 nn.Module。在初始化方法中，设置一个很小的常量 eps，创建一个可训练的参数张量 scale（初始化为全 1）和一个可训练的参数张量 shift（初始化为全 0），用于对标准化后的张量进行缩放和平移。

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)
        var = x.var(dim=-1, keepdim=True, unbiased=False)
        norm_x = (x - mean) / torch.sqrt(var + self.eps)
        return self.scale * norm_x + self.shift
        # 定义前向传播方法，接收输入张量 x，计算其均值和方差，对输入进行标准化，然后使用可训练的参数张量进行缩放和平移，并返回结果。
~~~
~~~
ln = LayerNorm(emb_dim=5)
out_ln = ln(batch_example)
mean = out_ln.mean(dim=-1, keepdim=True)
var = out_ln.var(dim=-1, unbiased=False, keepdim=True)

print("Mean:\n", mean)
print("Variance:\n", var)
# 创建一个 LayerNorm 类的实例，传入嵌入维度为 5。将之前创建的 batch_example 张量传入这个实例进行层归一化操作，然后计算归一化后张量的均值和方差，并打印结果。

class GELU(nn.Module):
    def __init__(self):
        super().__init__()
        # 定义一个 GELU 激活函数类，继承自 nn.Module，初始化方法中不做任何操作。

    def forward(self, x):
        return 0.5 * x * (1 + torch.tanh(
            torch.sqrt(torch.tensor(2.0 / torch.pi)) * 
            (x + 0.044715 * torch.pow(x, 3))
        ))
        # 定义前向传播方法，实现 GELU 激活函数的计算公式。

import matplotlib.pyplot as plt

gelu, relu = GELU(), nn.ReLU()
# 创建 GELU 激活函数类的实例和 ReLU 激活函数的实例。

# Some sample data
x = torch.linspace(-3, 3, 100)
y_gelu, y_relu = gelu(x), relu(x)
# 创建一个从 -3 到 3 的等间隔的张量 x，包含 100 个元素。分别将 x 传入 GELU 和 ReLU 激活函数实例，得到对应的输出张量 y_gelu 和 y_relu。

plt.figure(figsize=(8, 3))
for i, (y, label) in enumerate(zip([y_gelu, y_relu], ["GELU", "ReLU"]), 1):
    plt.subplot(1, 2, i)
    plt.plot(x, y)
    plt.title(f"{label} activation function")
    plt.xlabel("x")
    plt.ylabel(f"{label}(x)")
    plt.grid(True)
# 使用 matplotlib 创建一个图形，将图形分为两个子图，分别绘制 GELU 和 ReLU 激活函数的曲线，并设置标题、坐标轴标签和网格。

plt.tight_layout()
plt.show()
# 调整图形布局并显示图形。

class FeedForward(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(cfg["emb_dim"], 4 * cfg["emb_dim"]),
            GELU(),
            nn.Linear(4 * cfg["emb_dim"], cfg["emb_dim"]),
        )
        # 定义一个前馈神经网络类，继承自 nn.Module。在初始化方法中，创建一个包含线性层、GELU 激活函数和线性层的序列模型，使用配置字典中的嵌入维度参数。

    def forward(self, x):
        return self.layers(x)
        # 定义前向传播方法，将输入张量 x 传入序列模型，返回输出结果。

print(GPT_CONFIG_124M["emb_dim"])
# 打印配置字典中 GPT_CONFIG_124M 的嵌入维度参数。
~~~
~~~
ffn = FeedForward(GPT_CONFIG_124M)
# 创建一个 FeedForward 类的实例，传入配置字典 GPT_CONFIG_124M。

# input shape: [batch_size, num_token, emb_size]
x = torch.rand(2, 3, 768)
# 创建一个形状为 (2, 3, 768) 的随机张量，代表输入数据，其中 2 是批次大小，3 是标记数量，768 是嵌入维度。

out = ffn(x)
print(out.shape)
# 将输入张量传入 FeedForward 实例的前向传播方法，得到输出张量，并打印输出张量的形状。
~~~
~~~
class ExampleDeepNeuralNetwork(nn.Module):
    def __init__(self, layer_sizes, use_shortcut):
        super().__init__()
        self.use_shortcut = use_shortcut
        # 初始化方法接收层大小列表和一个布尔值，表示是否使用快捷连接（shortcut）。

        self.layers = nn.ModuleList([
            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),
            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),
            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),
            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),
            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())
        ])
        # 创建一个包含多个线性层和 GELU 激活函数的模块列表。

    def forward(self, x):
        for layer in self.layers:
            layer_output = layer(x)
            # 计算当前层的输出。

            if self.use_shortcut and x.shape == layer_output.shape:
                x = x + layer_output
            else:
                x = layer_output
            # 如果使用快捷连接并且输入和当前层输出形状相同，则将输入和输出相加，否则直接使用输出作为下一层的输入。

        return x
        # 返回最终的输出。

def print_gradients(model, x):
    # Forward pass
    output = model(x)
    target = torch.tensor([[0.]])
    # 进行前向传播，计算模型的输出，并定义一个目标张量。
    # Calculate loss based on how close the target
    # and output are
    loss = nn.MSELoss()
    loss = loss(output, target)
    # 使用均方误差损失函数计算输出和目标之间的损失。

    # Backward pass to calculate the gradients
    loss.backward()
    # 进行反向传播，计算模型参数的梯度。

    for name, param in model.named_parameters():
        if 'weight' in name:
            # Print the mean absolute gradient of the weights
            print(f"{name} has gradient mean of {param.grad.abs().mean()}")
            # 遍历模型的参数，如果参数名称中包含'weight'，则打印该参数的梯度的均值绝对值。

layer_sizes = [3, 3, 3, 3, 3, 1]  
sample_input = torch.tensor([[1., 0., -1.]])
# 定义层大小列表和一个样本输入张量。

torch.manual_seed(123)
model_without_shortcut = ExampleDeepNeuralNetwork(
    layer_sizes, use_shortcut=False
)
print_gradients(model_without_shortcut, sample_input)
# 设置随机种子，创建一个不使用快捷连接的模型实例，并调用 print_gradients 函数打印该模型参数的梯度信息。

torch.manual_seed(123)
model_with_shortcut = ExampleDeepNeuralNetwork(
    layer_sizes, use_shortcut=True
)
print_gradients(model_with_shortcut, sample_input)
# 设置相同的随机种子，创建一个使用快捷连接的模型实例，并调用 print_gradients 函数打印该模型参数的梯度信息。
~~~
~~~
from previous_chapters import MultiHeadAttention
# 从之前的章节中导入 MultiHeadAttention 模块。

class TransformerBlock(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        self.att = MultiHeadAttention(
            d_in=cfg["emb_dim"],
            d_out=cfg["emb_dim"],
            context_length=cfg["context_length"],
            num_heads=cfg["n_heads"], 
            dropout=cfg["drop_rate"],
            qkv_bias=cfg["qkv_bias"])
        self.ff = FeedForward(cfg)
        self.norm1 = LayerNorm(cfg["emb_dim"])
        self.norm2 = LayerNorm(cfg["emb_dim"])
        self.drop_shortcut = nn.Dropout(cfg["drop_rate"])
        # 初始化方法中，创建多头注意力模块（MultiHeadAttention）、前馈神经网络模块（FeedForward）、两个层归一化模块（LayerNorm）和一个 dropout 模块（nn.Dropout）。

    def forward(self, x):
        # Shortcut connection for attention block
        shortcut = x
        x = self.norm1(x)
        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]
        x = self.drop_shortcut(x)
        x = x + shortcut  # Add the original input back
        # 对于注意力模块，先保存输入的快捷连接，然后对输入进行层归一化，通过多头注意力模块处理，进行 dropout，最后加上快捷连接。

        # Shortcut connection for feed forward block
        shortcut = x
        x = self.norm2(x)
        x = self.ff(x)
        x = self.drop_shortcut(x)
        x = x + shortcut  # Add the original input back
        # 对于前馈神经网络模块，同样先保存输入的快捷连接，然后对输入进行层归一化，通过前馈神经网络模块处理，进行 dropout，最后加上快捷连接。

        return x
        # 返回经过两个模块处理后的输出。

torch.manual_seed(123)
x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]
block = TransformerBlock(GPT_CONFIG_124M)
output = block(x)

print("Input shape:", x.shape)
print("Output shape:", output.shape)
# 设置随机种子，创建一个随机输入张量，形状为 [batch_size, num_tokens, emb_dim]。创建一个 TransformerBlock 类的实例，传入配置字典。将输入张量传入实例的前向传播方法，得到输出张量，并打印输入和输出张量的形状。
~~~
~~~
class GPTModel(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        self.tok_emb = nn.Embedding(cfg["vocab_size"], cfg["emb_dim"])
        self.pos_emb = nn.Embedding(cfg["context_length"], cfg["emb_dim"])
        self.drop_emb = nn.Dropout(cfg["drop_rate"])
        # 创建词嵌入层、位置嵌入层和 dropout 层，使用配置字典中的参数进行初始化。

        self.trf_blocks = nn.Sequential(
            *[TransformerBlock(cfg) for _ in range(cfg["n_layers"])])
        # 创建一个由多个 TransformerBlock 组成的序列模型，代表多个 Transformer 层。

        self.final_norm = LayerNorm(cfg["emb_dim"])
        self.out_head = nn.Linear(
            cfg["emb_dim"], cfg["vocab_size"], bias=False
        )
        # 创建一个层归一化模块和一个线性输出层，将嵌入维度转换为词汇表大小。

    def forward(self, in_idx):
        batch_size, seq_len = in_idx.shape
        tok_embeds = self.tok_emb(in_idx)
        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))
        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]
        x = self.drop_emb(x)
        x = self.trf_blocks(x)
        x = self.final_norm(x)
        logits = self.out_head(x)
        return logits
        # 定义前向传播方法，接收输入索引张量，计算词嵌入和位置嵌入，将它们相加后经过 dropout、多个 Transformer 层、层归一化和线性输出层，返回预测的 logits。
torch.manual_seed(123)
model = GPTModel(GPT_CONFIG_124M)
# 设置随机种子，创建 GPTModel 类的实例，传入配置字典。
out = model(batch)
print("Input batch:\n", batch)
print("\nOutput shape:", out.shape)
print(out)
# 将之前创建的批次张量传入模型实例的前向传播方法，得到输出张量，打印输入批次张量、输出张量的形状和输出张量的值。
total_params = sum(p.numel() for p in model.parameters())
print(f"Total number of parameters: {total_params:,}")
# 计算模型中所有参数的总数，并打印结果。
print("Token embedding layer shape:", model.tok_emb.weight.shape)
print("Output layer shape:", model.out_head.weight.shape)
# 打印词嵌入层和输出层的权重形状。
total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())
print(f"Number of trainable parameters considering weight tying: {total_params_gpt2:,}")
# 考虑权重绑定的情况，计算除输出层之外的可训练参数的数量，并打印结果。
~~~
~~~
# Calculate the total size in bytes (assuming float32, 4 bytes per parameter)
total_size_bytes = total_params * 4
# 计算模型的总大小（以字节为单位），假设每个参数占用 4 个字节（float32 类型）。
# Convert to megabytes
total_size_mb = total_size_bytes / (1024 * 1024)
# 将字节转换为兆字节。
print(f"Total size of the model: {total_size_mb:.2f} MB")
# 打印模型的总大小（以兆字节为单位），保留两位小数。
def generate_text_simple(model, idx, max_new_tokens, context_size):
    # idx is (batch, n_tokens) array of indices in the current context
    for _ in range(max_new_tokens):
        # 循环生成新的 tokens，次数为 max_new_tokens。
        # Crop current context if it exceeds the supported context size
        # E.g., if LLM supports only 5 tokens, and the context size is 10
        # then only the last 5 tokens are used as context
        idx_cond = idx[:, -context_size:]
        # 如果当前上下文超过支持的上下文大小，则裁剪上下文，只取最后 context_size 个 tokens 作为新的上下文。
        # Get the predictions
        with torch.no_grad():
            logits = model(idx_cond)
        # 在不计算梯度的情况下，使用模型预测新的 logits。
        # Focus only on the last time step
        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)
        logits = logits[:, -1, :]
        # 只关注最后一个时间步的 logits，将形状从 (batch, n_tokens, vocab_size) 变为 (batch, vocab_size)。
        # Apply softmax to get probabilities
        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)
        # 对 logits 应用 softmax 函数得到概率分布。
        # Get the idx of the vocab entry with the highest probability value
        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)
        # 获取概率最高的词汇表索引。
        # Append sampled index to the running sequence
        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)
        # 将采样得到的索引添加到当前序列中。
    return idx
    # 返回生成的序列。
start_context = "Hello, I am"
encoded = tokenizer.encode(start_context)
print("encoded:", encoded)
# 对起始上下文进行编码，并打印编码结果。
encoded_tensor = torch.tensor(encoded).unsqueeze(0)
print("encoded_tensor.shape:", encoded_tensor.shape)
# 将编码结果转换为张量，并增加一个维度表示批次，打印张量的形状。
model.eval()  # disable dropout
# 将模型设置为评估模式，禁用 dropout。
out = generate_text_simple(
    model=model,
    idx=encoded_tensor,
    max_new_tokens=6,
    context_size=GPT_CONFIG_124M["context_length"]
)
# 使用生成文本的函数生成新的文本，传入模型、起始张量、最大新生成 tokens 数量和上下文大小。
print("Output:", out)
print("Output length:", len(out[0]))
# 打印生成的结果和结果的长度。
decoded_text = tokenizer.decode(out.squeeze(0).tolist())
print(decoded_text)
# 将生成的结果解码为文本，并打印解码后的文本。
~~~
~~~

~~~